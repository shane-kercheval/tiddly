# UUIDv7 Primary Key Implementation Plan

## Overview

Replace sequential integer primary keys with UUIDv7 for all content tables. This eliminates information leakage from auto-increment IDs while providing time-sortable, globally unique identifiers.

### Problem

Current auto-increment integer IDs leak information:
- Competitors can infer total record counts ("my bookmark is ID 50,000")
- Growth rates can be estimated by creating accounts over time
- Sequential IDs provide enumeration surface for attackers

### Solution: UUIDv7 as Sole Primary Key

Replace integer PKs with UUIDv7:
- **Single ID**: One `id` column that is both the PK and API identifier
- **Time-sortable**: UUIDv7 embeds a Unix timestamp (millisecond precision)
- **Native PostgreSQL**: Uses `uuid` type (16 bytes binary, efficient indexing)
- **No information leakage**: Random component prevents inference
- **Distributed-ready**: IDs can be generated on any node without coordination (enables future sharding, multi-region, microservices)

### Why UUIDv7 Over Other Options

| Option | Storage | Time-sortable | Native PG type | Standard |
|--------|---------|---------------|----------------|----------|
| UUIDv4 | 16 bytes | No | Yes | RFC 4122 |
| UUIDv7 | 16 bytes | Yes | Yes | RFC 9562 |
| ULID | 26 bytes (string) | Yes | No | Informal |
| Dual ID | 4+26 bytes | N/A | N/A | N/A |

**UUIDv7 wins because:**
1. Native PostgreSQL `uuid` type = smaller storage, better indexing than string-based ULID
2. Time-sortable = sequential insert performance (unlike UUIDv4)
3. RFC 9562 standard = better interoperability
4. Simpler than dual-ID approach = less code, fewer migrations, no mapping logic

### Tables to Migrate

Based on API analysis, these tables expose integer IDs:

| Table | API Exposure | Foreign Keys |
|-------|--------------|--------------|
| `bookmarks` | `/bookmarks/{id}`, responses | `user_id`, junction tables |
| `notes` | `/notes/{id}`, responses | `user_id`, junction tables |
| `prompts` | `/prompts/{id}`, responses | `user_id`, junction tables |
| `content_lists` | `/lists/{id}`, responses, `list_id` query params | `user_id` |
| `tags` | Tag responses, rename endpoint | `user_id`, junction tables |
| `api_tokens` | `/tokens/{id}`, responses | `user_id` |

**Tables NOT migrated:**
- `users`: Internal-only ID (Auth0 users never see it; exposed ID is `auth0_id`)
- `user_consent`: Internal-only (consent endpoint returns consent data, not ID)
- `user_settings`: Internal-only (settings endpoint returns settings, not ID)
- Junction tables (`bookmark_tags`, etc.): Will be updated to reference new UUIDs

### Key Design Decisions

1. **UUID generation**: Generate in Python at model instantiation using `uuid7` library
2. **Field name unchanged**: API continues using `id` - only the type changes (`int` → `str`)
3. **URL format**: UUIDs with hyphens are URL-safe (e.g., `/bookmarks/01938a12-3b45-7c67-8d90-ef1234567890`)
4. **Minimal breaking change**: Only the type changes; clients using `/bookmarks/${bookmark.id}` continue working
5. **Single migration**: All tables migrated in one atomic transaction

### Documentation

Read before implementing:
- UUIDv7 RFC 9562: https://www.rfc-editor.org/rfc/rfc9562#name-uuid-version-7
- uuid7 Python library: https://pypi.org/project/uuid7/

---

## Milestone 1: Add UUID7 Library and Create ID Mixin

### Goal
Add UUIDv7 generation capability and create a mixin that replaces integer PKs.

### Success Criteria
- `uuid7` library installed
- `UUIDv7Mixin` created that defines `id` as UUID primary key
- UUID auto-generates on model instantiation
- Unit tests verify UUID generation and format

### Key Changes

**1. Add dependency:**

```bash
uv add uuid7
```

**2. Create `UUIDv7Mixin` in `backend/src/models/base.py`:**

```python
from uuid import UUID
from uuid7 import uuid7
from sqlalchemy.dialects.postgresql import UUID as PG_UUID

class UUIDv7Mixin:
    """Mixin that provides a UUIDv7 primary key."""

    id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True),
        primary_key=True,
        default=uuid7,
    )
```

Notes:
- `uuid7()` returns a standard `uuid.UUID` object
- `as_uuid=True` means SQLAlchemy handles UUID↔string conversion automatically
- No need for `str(uuid7())` - the type is native

### Testing Strategy
- Test UUID is auto-generated when not provided
- Test UUID format is valid (version 7, correct structure)
- Test UUIDs are time-ordered (create two in sequence, confirm ordering)
- Test custom UUID can be provided (for testing/seeding)

### Dependencies
None - this is the foundation.

### Risk Factors
- Verify `default=uuid7` works correctly with SQLAlchemy (function reference, not call)

---

## Milestone 2: Database Migration (All Tables)

### Goal
Single Alembic migration that converts all 6 tables from integer PKs to UUIDv7 PKs, including updating all 3 junction table foreign keys.

### Success Criteria
- All tables converted: `bookmarks`, `notes`, `prompts`, `content_lists`, `tags`, `api_tokens`
- All junction tables updated: `bookmark_tags`, `note_tags`, `prompt_tags`
- Migration is atomic (all or nothing)
- Migration tested against production backup
- Rollback documented (restore from backup)

### Key Changes

**Create single Alembic migration:**

```bash
make migration message="convert all content tables to uuid7 primary keys"
```

**Migration script structure:**

```python
"""Convert all content tables to UUID7 primary keys.

Tables converted:
- bookmarks (+ bookmark_tags junction)
- notes (+ note_tags junction)
- prompts (+ prompt_tags junction)
- content_lists
- tags
- api_tokens

Revision ID: xxxx
"""
from uuid7 import uuid7
from sqlalchemy.dialects.postgresql import UUID as PG_UUID
import sqlalchemy as sa
from alembic import op

# Tables with junction table dependencies
TABLES_WITH_JUNCTIONS = {
    'bookmarks': 'bookmark_tags',
    'notes': 'note_tags',
    'prompts': 'prompt_tags',
}

# Tables without junction dependencies
SIMPLE_TABLES = ['content_lists', 'tags', 'api_tokens']


def get_pk_constraint_name(connection, table_name: str) -> str:
    """Query actual primary key constraint name from database."""
    result = connection.execute(sa.text("""
        SELECT constraint_name FROM information_schema.table_constraints
        WHERE table_name = :table AND constraint_type = 'PRIMARY KEY'
    """), {"table": table_name})
    return result.scalar()


def get_fk_constraint_name(connection, table_name: str, column_name: str) -> str:
    """Query actual foreign key constraint name from database."""
    result = connection.execute(sa.text("""
        SELECT tc.constraint_name
        FROM information_schema.table_constraints tc
        JOIN information_schema.key_column_usage kcu
            ON tc.constraint_name = kcu.constraint_name
        WHERE tc.table_name = :table
            AND tc.constraint_type = 'FOREIGN KEY'
            AND kcu.column_name = :column
    """), {"table": table_name, "column": column_name})
    return result.scalar()


def convert_table_with_junction(table_name: str, junction_table: str) -> None:
    """Convert a table and its junction table FK to UUID."""
    connection = op.get_bind()
    fk_column = f"{table_name[:-1]}_id"  # bookmarks -> bookmark_id

    # Query actual constraint names (don't assume naming convention)
    pk_name = get_pk_constraint_name(connection, table_name)
    fk_name = get_fk_constraint_name(connection, junction_table, fk_column)

    # 1. Add new UUID column to main table
    op.add_column(table_name, sa.Column('new_id', PG_UUID(as_uuid=True), nullable=True))

    # 2. Generate UUIDs for existing rows
    rows = connection.execute(sa.text(f"SELECT id FROM {table_name}"))
    for row in rows:
        new_uuid = uuid7()
        connection.execute(
            sa.text(f"UPDATE {table_name} SET new_id = :new_id WHERE id = :old_id"),
            {"new_id": str(new_uuid), "old_id": row.id}
        )

    # 3. Make new_id non-nullable
    op.alter_column(table_name, 'new_id', nullable=False)

    # 4. Add new FK column to junction table
    op.add_column(junction_table, sa.Column(f'new_{fk_column}', PG_UUID(as_uuid=True), nullable=True))

    # 5. Copy FK references
    connection.execute(sa.text(f"""
        UPDATE {junction_table} jt
        SET new_{fk_column} = t.new_id
        FROM {table_name} t
        WHERE jt.{fk_column} = t.id
    """))

    # 6. Drop old constraints (using actual names from database)
    op.drop_constraint(fk_name, junction_table, type_='foreignkey')
    op.drop_constraint(pk_name, table_name, type_='primary')

    # 7. Drop old columns
    op.drop_column(junction_table, fk_column)
    op.drop_column(table_name, 'id')

    # 8. Rename new columns
    op.alter_column(table_name, 'new_id', new_column_name='id')
    op.alter_column(junction_table, f'new_{fk_column}', new_column_name=fk_column)

    # 9. Recreate constraints
    op.create_primary_key(f'{table_name}_pkey', table_name, ['id'])
    op.create_foreign_key(
        f'{junction_table}_{fk_column}_fkey', junction_table,
        table_name, [fk_column], ['id'], ondelete='CASCADE'
    )


def convert_simple_table(table_name: str) -> None:
    """Convert a table without junction dependencies to UUID."""
    connection = op.get_bind()

    # Query actual constraint name (don't assume naming convention)
    pk_name = get_pk_constraint_name(connection, table_name)

    # 1. Add new UUID column
    op.add_column(table_name, sa.Column('new_id', PG_UUID(as_uuid=True), nullable=True))

    # 2. Generate UUIDs for existing rows
    rows = connection.execute(sa.text(f"SELECT id FROM {table_name}"))
    for row in rows:
        new_uuid = uuid7()
        connection.execute(
            sa.text(f"UPDATE {table_name} SET new_id = :new_id WHERE id = :old_id"),
            {"new_id": str(new_uuid), "old_id": row.id}
        )

    # 3. Make non-nullable
    op.alter_column(table_name, 'new_id', nullable=False)

    # 4. Drop old PK (using actual name from database)
    op.drop_constraint(pk_name, table_name, type_='primary')

    # 5. Drop old column
    op.drop_column(table_name, 'id')

    # 6. Rename new column
    op.alter_column(table_name, 'new_id', new_column_name='id')

    # 7. Recreate PK
    op.create_primary_key(f'{table_name}_pkey', table_name, ['id'])


def upgrade() -> None:
    # Convert tables with junction dependencies first
    for table_name, junction_table in TABLES_WITH_JUNCTIONS.items():
        convert_table_with_junction(table_name, junction_table)

    # Convert simple tables
    for table_name in SIMPLE_TABLES:
        convert_simple_table(table_name)

    # Recreate any dropped indexes
    # bookmarks: partial unique index on user_id + url
    op.create_index(
        'uq_bookmark_user_url_active', 'bookmarks',
        ['user_id', 'url'], unique=True,
        postgresql_where=sa.text("deleted_at IS NULL")
    )

    # Junction table indexes (tag_id lookups)
    op.create_index('ix_bookmark_tags_tag_id', 'bookmark_tags', ['tag_id'])
    op.create_index('ix_note_tags_tag_id', 'note_tags', ['tag_id'])
    op.create_index('ix_prompt_tags_tag_id', 'prompt_tags', ['tag_id'])


def downgrade() -> None:
    # Downgrade not supported - restore from backup instead
    raise NotImplementedError(
        "Downgrade not supported for PK type change. Restore from backup."
    )
```

**Important notes for the agent:**
- The migration queries actual constraint names from the database (no hardcoded assumptions)
- The `tags` table has a unique constraint on `(user_id, name)` that may need recreation
- Test thoroughly against backup before production

### Testing Strategy

**1. Local testing:**
```bash
# Run existing tests - they should fail until Milestone 3 updates the code
make unit_tests
```

**2. Pre-production testing against backup:**

```bash
# 1. Set environment variables
export PROD_DATABASE_URL="postgresql://postgres:..."
export BACKUP_DATABASE_URL="postgresql://postgres:..."

# 2. Copy production database to backup
PGSSLMODE=require pg_dump --dbname="$PROD_DATABASE_URL" -F c \
  | PGSSLMODE=require pg_restore --clean --if-exists --no-owner --no-privileges \
    --dbname="$BACKUP_DATABASE_URL"

# 3. Run migration against backup
DATABASE_URL="$BACKUP_DATABASE_URL" uv run alembic upgrade head

# 4. Verify all tables have UUID PKs
for table in bookmarks notes prompts content_lists tags api_tokens; do
  echo "Checking $table..."
  PGSSLMODE=require psql "$BACKUP_DATABASE_URL" -c \
    "SELECT column_name, data_type FROM information_schema.columns
     WHERE table_name = '$table' AND column_name = 'id';"
done
# All should show data_type = 'uuid'

# 5. Verify no NULL IDs
for table in bookmarks notes prompts content_lists tags api_tokens; do
  PGSSLMODE=require psql "$BACKUP_DATABASE_URL" -c \
    "SELECT COUNT(*) as null_ids FROM $table WHERE id IS NULL;"
done
# All should return 0

# 6. Verify junction table FK integrity
for jt in bookmark_tags note_tags prompt_tags; do
  echo "Checking $jt..."
  # Extract parent table name (bookmark_tags -> bookmarks)
  parent="${jt%_tags}s"
  fk_col="${jt%_tags}_id"
  PGSSLMODE=require psql "$BACKUP_DATABASE_URL" -c \
    "SELECT COUNT(*) as orphaned FROM $jt jt
     LEFT JOIN $parent p ON jt.$fk_col = p.id
     WHERE p.id IS NULL;"
done
# All should return 0

# 7. Verify row counts match pre-migration
# (Compare against counts you recorded before migration)
```

### Dependencies
Milestone 1 (UUIDv7Mixin must exist)

### Risk Factors
- **Backup required**: Always backup before running on production
- **No downgrade**: Rollback means restoring from backup

---

## Milestone 3: Update Backend Code

### Goal
Update all models, schemas, routers, and services to use UUID strings instead of integers.

### Success Criteria
- All 6 models use `UUIDv7Mixin`
- All schemas have `id: str`
- All routers have `str` path parameters
- All services have updated type hints
- All existing tests pass (with updates for string IDs)

### Key Changes

**1. Update models to use UUIDv7Mixin:**

Remove `id: Mapped[int] = mapped_column(primary_key=True)` from each model and add `UUIDv7Mixin`:

```python
# backend/src/models/bookmark.py
from models.base import ArchivableMixin, Base, TimestampMixin, UUIDv7Mixin

class Bookmark(Base, TimestampMixin, ArchivableMixin, UUIDv7Mixin):
    __tablename__ = "bookmarks"
    # Remove: id: Mapped[int] = mapped_column(primary_key=True)
    # ... rest unchanged
```

Apply same pattern to:
- `backend/src/models/note.py`
- `backend/src/models/prompt.py`
- `backend/src/models/content_list.py`
- `backend/src/models/tag.py`
- `backend/src/models/api_token.py`

**2. Update junction table definitions in `backend/src/models/tag.py`:**

```python
from sqlalchemy.dialects.postgresql import UUID as PG_UUID

bookmark_tags = Table(
    "bookmark_tags",
    Base.metadata,
    Column(
        "bookmark_id",
        PG_UUID(as_uuid=True),  # Changed from Integer
        ForeignKey("bookmarks.id", ondelete="CASCADE"),
        primary_key=True,
    ),
    Column(
        "tag_id",
        PG_UUID(as_uuid=True),  # Changed from Integer
        ForeignKey("tags.id", ondelete="CASCADE"),
        primary_key=True,
    ),
    Index("ix_bookmark_tags_tag_id", "tag_id"),
)
# Same for note_tags and prompt_tags
```

**3. Update schemas - change `id: int` to `id: str`:**

Files to update:
- `backend/src/schemas/bookmark.py`: `BookmarkListItem`, `BookmarkResponse`
- `backend/src/schemas/note.py`: `NoteListItem`, `NoteResponse`
- `backend/src/schemas/prompt.py`: `PromptListItem`, `PromptResponse`
- `backend/src/schemas/content_list.py`: `ContentListResponse`
- `backend/src/schemas/tag.py`: `TagResponse`
- `backend/src/schemas/token.py`: `TokenResponse`

Example:
```python
class BookmarkListItem(BaseModel):
    model_config = ConfigDict(from_attributes=True)

    id: str  # Changed from int
    # ... rest unchanged
```

**4. Update routers - use UUID type for path parameters:**

Using `UUID` type directly provides automatic 422 validation on malformed UUIDs (instead of letting invalid strings propagate to the database):

```python
from uuid import UUID

@router.get("/{bookmark_id}")
async def get_bookmark(bookmark_id: UUID) -> BookmarkResponse:
    # FastAPI automatically returns 422 if bookmark_id is not a valid UUID
    ...
```

Files to update:
- `backend/src/api/routers/bookmarks.py`: `bookmark_id: int` → `bookmark_id: UUID`
- `backend/src/api/routers/notes.py`: `note_id: int` → `note_id: UUID`
- `backend/src/api/routers/prompts.py`: `prompt_id: int` → `prompt_id: UUID`
- `backend/src/api/routers/lists.py`: `list_id: int` → `list_id: UUID`
- `backend/src/api/routers/tags.py`: `tag_id: int` → `tag_id: UUID`
- `backend/src/api/routers/tokens.py`: `token_id: int` → `token_id: UUID`

Also update `list_id` query parameters in bookmarks, notes, prompts routers to `UUID | None`.

**5. Update services - change type hints:**

Files to update:
- `backend/src/services/bookmark_service.py`
- `backend/src/services/note_service.py`
- `backend/src/services/prompt_service.py`
- `backend/src/services/list_service.py`
- `backend/src/services/tag_service.py`
- `backend/src/services/token_service.py`

Example:
```python
from uuid import UUID

async def get_bookmark(
    session: AsyncSession,
    user_id: int,  # user_id stays int (users table not migrated)
    bookmark_id: UUID,  # Changed from int
    ...
) -> Bookmark | None:
```

**6. Update TaggableEntity Protocol in `backend/src/services/base_entity_service.py`:**

```python
from uuid import UUID

class TaggableEntity(Protocol):
    """Protocol defining the interface for entities that support tagging and soft-delete."""

    id: UUID  # Changed from int
    user_id: int  # Stays int (users table not migrated)
    # ... rest unchanged
```

Also update `entity_id: int` parameters in `BaseEntityService` methods to `entity_id: UUID`.

### Testing Strategy

**Update existing tests:**

```bash
# Find all tests that need updates
grep -rn "\.id == [0-9]" backend/tests/
grep -rn '"id": [0-9]' backend/tests/
grep -rn "_id: int" backend/tests/
grep -rn "bookmark_id=" backend/tests/
grep -rn "note_id=" backend/tests/
grep -rn "prompt_id=" backend/tests/
```

Common patterns to update:
- `assert response.json()["id"] == 1` → `assert isinstance(response.json()["id"], str)` and validate UUID format
- `bookmark_id: int` → `bookmark_id: UUID`
- Integer comparisons → UUID comparisons

**New tests to add:**
- Test 422 returned for malformed UUID path parameters (e.g., `/bookmarks/not-a-uuid`)
- Test 404 returned for valid UUID that doesn't exist

**Run full test suite:**
```bash
make tests  # Runs linting + all backend + frontend tests
```

### Dependencies
Milestone 2 (database must be migrated)

### Risk Factors
- Many files to update - use grep to find all occurrences
- Test fixtures may create entities with hardcoded integer IDs

---

## Milestone 4: Update MCP Servers

### Goal
Update MCP servers to use UUID strings for ID parameters.

### Success Criteria
- MCP tools accept `id` parameters as `str`
- MCP server tests pass

### Key Changes

**1. Update `backend/src/mcp_server/server.py`:**

```python
# get_bookmark
bookmark_id: Annotated[str, Field(description="The UUID of the bookmark to retrieve")]

# get_note
note_id: Annotated[str, Field(description="The UUID of the note to retrieve")]
```

**2. Update `backend/src/prompt_mcp_server/server.py`:**

Similar changes for any prompt ID parameters.

### Testing Strategy
- Test `get_bookmark` and `get_note` work with UUID string IDs
- Test 404 returned for invalid/nonexistent UUID
- Run MCP server tests

### Dependencies
Milestone 3 (backend code must be updated)

### Risk Factors
Very low risk - minimal code changes

---

## Milestone 5: Update Frontend

### Goal
Update frontend TypeScript types to expect `id` as string.

### Success Criteria
- TypeScript types use `id: string` instead of `id: number`
- All existing code using `bookmark.id`, `note.id`, etc. continues working
- URL routes continue working
- All frontend tests pass
- TypeScript compiles without errors

### Key Changes

**1. Update `frontend/src/types.ts`:**

```typescript
export interface BookmarkListItem {
  id: string  // Changed from number
  // ... rest unchanged
}

export interface NoteListItem {
  id: string  // Changed from number
  // ...
}

export interface PromptListItem {
  id: string  // Changed from number
  // ...
}

export interface ContentList {
  id: string  // Changed from number
  // ...
}

export interface Tag {
  id: string  // Changed from number
  // ...
}

export interface Token {
  id: string  // Changed from number
  // ...
}

export interface ContentListItem {
  id: string  // Changed from number
  // ...
}

export interface SidebarListItem {
  type: 'list'
  id: string  // Changed from number
}

// Update query param types
export interface NoteSearchParams {
  // ...
  list_id?: string  // Changed from number
}

export interface BookmarkSearchParams {
  // ...
  list_id?: string  // Changed from number
}

export interface PromptSearchParams {
  // ...
  list_id?: string  // Changed from number
}

export interface ContentSearchParams {
  // ...
  list_id?: string  // Changed from number
}
```

**2. Search for any numeric operations on IDs:**

```bash
cd frontend
grep -rn "\.id ===" src/
grep -rn "\.id ==" src/
grep -rn "\.id <" src/
grep -rn "\.id >" src/
grep -rn "parseInt.*id" src/
grep -rn "Number.*id" src/
```

Fix any code that treats IDs as numbers.

### Testing Strategy

```bash
cd frontend

# TypeScript compilation
npm run build

# Run tests
npm run test:run

# Linting
npm run lint
```

Manual testing:
- Create, read, update, delete bookmarks/notes/prompts
- Navigate via URLs
- Test list filtering with `list_id`

### Dependencies
All backend milestones complete

### Risk Factors
- Any code comparing IDs as numbers would break
- Any code parsing IDs as integers would break

---

## Summary

| Milestone | Component | Scope |
|-----------|-----------|-------|
| 1 | Foundation | `uuid7` library + `UUIDv7Mixin` |
| 2 | Database Migration | Single migration for all 6 tables + 3 junction tables |
| 3 | Backend Code | Models, schemas, routers, services |
| 4 | MCP Servers | ID parameter types |
| 5 | Frontend | TypeScript types |

Total: 5 milestones. Each milestone should be reviewed before proceeding to the next.

### Migration Workflow

1. **Milestone 1**: Add library and mixin (no DB changes)
2. **Milestone 2**: Write and test migration
   - Test locally with `make unit_tests`
   - Clone production DB to backup
   - Run migration against backup
   - Verify all tables and FK integrity
3. **Milestone 3**: Update backend code, fix tests
4. **Milestone 4**: Update MCP servers
5. **Milestone 5**: Update frontend
6. **Deploy**: Run migration on production, deploy new code

### Important Notes

- **No backwards compatibility**: Old integer IDs will not work after migration
- **API breaking change**: Clients must update to expect string IDs
- **Database backup required**: Test migration on backup before production
- **Downgrade not supported**: Rollback means restoring from pre-migration backup
- **Atomic migration**: All tables converted in single transaction
